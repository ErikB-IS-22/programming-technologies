Цель лабораторной работы: установить на рабочую машину локальную модель нейросети Qwen и запустить её. Перед началом работы необходимо было установить Python, WebUI для интеракций с языковой моделью и непосредственно саму модель Qwen. Для выполнения задания была использована версия Python 3.12.10, установлен text-generation-webui по ссылке https://github.com/oobabooga/text-generation-webui и модель Qwen Qwen2.5-Omni-3B-GGUF. После копирования text-generation-webui модель была добавлена в WebUI.
Чтобы запустить WebUI, была выполнена команда python server.py и был выполнен переход по ссылке (рис. 1). После запуска был открыт интерфейс WebUI (рис. 2). Далее во вкладке Model была выбрана и загружена модель Qwen.

<img width="974" height="131" alt="image" src="https://github.com/user-attachments/assets/a207fd1b-1974-433f-8ced-7a7f8a2457af" />

Рисунок 1 – Запуск WebUI

<img width="974" height="522" alt="image" src="https://github.com/user-attachments/assets/72b7fba3-3f7e-440c-a62e-ea00686c20bb" />

Рисунок 2 – Интерфейс WebUI

	После загрузки модели, модель была протестирована с помощью простых промптов (рис. 3), также модель была протестирована с другими режимами диалога (chat, chat-instruct, instruct).
	
<img width="761" height="157" alt="image" src="https://github.com/user-attachments/assets/04f5d06a-fcf8-4530-83bf-a283e1714a92" />

Рисунок 3 – Тестирование модели

	Далее по требованию задания был настроен системный промпт. Был выбран системный промпт Alpaca. Для этого во вкладке Parameters >> Instruction templates, а затем Model >> Custom Instruction Template был выбран соответствующий промпт (рис. 4). После этого модель с новым системным промптом также была протестирована (рис. 5).
	
<img width="961" height="516" alt="image" src="https://github.com/user-attachments/assets/8163b0ac-2e36-455a-b0f4-72d3eb5a8273" />
<img width="632" height="306" alt="image" src="https://github.com/user-attachments/assets/9a2ef3ae-0d6d-4da5-90fd-bb2fbc5a7141" />

Рисунок 4 – Настройка системного промпта.

<img width="849" height="286" alt="image" src="https://github.com/user-attachments/assets/d86b8909-e2de-4206-8e86-bb732a73f363" />

Рисунок 5 – Тестирование системного промпта Alpaca

Вторым задание было тестирование другой модели. В качестве другой модели была выбрана Qwen2.5-Omni-3B-Q8_0, которая также была протестирована (рис. 6).

<img width="783" height="955" alt="image" src="https://github.com/user-attachments/assets/658307d7-ceef-4073-bf90-bc5415f79f9c" />

Рисунок 6 – Тестирование модели Qwen2.5-Omni-3B-Q8_0

	Третьим заданием были настройки различных параметров (temperature, top_p, top_k, repetition_penalty, и т.д.). Эти настройки отвечают за случайность результатов:
•	temperature: основной фактор, контролирующий случайность выходных данных. 0 = детерминированный (используется только наиболее вероятный токен). Чем выше значение, тем выше случайность.
•	top_p: если не установлено значение 1, выбираются токены с суммой вероятностей меньше этого числа. Чем больше значение, тем шире диапазон возможных случайных результатов.
•	top_k: аналогично top_p, но выбирает только наиболее вероятные токены top_k. Чем больше значение, тем шире диапазон возможных случайных результатов.
•	repetition_penalty: Штрафной коэффициент за повторение предыдущих токенов. 1 означает отсутствие штрафа, большее значение = меньше повторений, меньшее значение = больше повторений.
Если выставить максимальные значения этих параметров (рис. 7), модель начнёт неадекватно себя вести (рис. 8).

<img width="481" height="599" alt="image" src="https://github.com/user-attachments/assets/a1400b0a-e551-47f8-9c22-740ed2f98cc6" />

Рисунок 7 – Изменение параметров модели

<img width="965" height="358" alt="image" src="https://github.com/user-attachments/assets/b2e3e8e1-f1eb-4946-ac32-980b73a7eb96" />

Рисунок 8 – Неадекватное поведение модели при выставлении максимальных значений параметров
